{
  "task_id": "2d226084-55a9-44db-85ef-308140b0ef81",
  "user_id": "test_matplotlib_fix",
  "task_type": "svm_classification",
  "params": {
    "data_source": "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv",
    "target_column": "species",
    "kernel": "linear",
    "optimize_hyperparameters": false,
    "n_trials": 1,
    "cv_folds": 2,
    "scoring_metric": null,
    "validate_data": true,
    "save_model": true,
    "apply_preprocessing": true,
    "scaling_method": "standard",
    "models_dir": "trained_models/test_matplotlib_fix"
  },
  "status": "completed",
  "created_at": "2025-09-22T02:16:08.250651",
  "started_at": "2025-09-22T02:16:08.250964",
  "completed_at": "2025-09-22T02:16:11.668272",
  "progress": 100.0,
  "error_message": null,
  "result": {
    "model_id": "e6f5579f-d5ef-48b2-ba67-48a80f15ef51",
    "algorithm": "SVM_Classification",
    "task_type": "classification",
    "kernel": "linear",
    "training_time_seconds": 3.412094,
    "data_shape": {
      "n_samples": 150,
      "n_features": 4
    },
    "feature_names": [
      "sepal_length",
      "sepal_width",
      "petal_length",
      "petal_width"
    ],
    "target_names": "species",
    "best_hyperparameters": {
      "kernel": "rbf",
      "C": 1.0,
      "gamma": "scale",
      "degree": 3
    },
    "feature_importance": {
      "permutation": {
        "sepal_length": {
          "importance_mean": 0.017333333333333402,
          "importance_std": 0.0053333333333333175
        },
        "sepal_width": {
          "importance_mean": 0.026666666666666727,
          "importance_std": 0.005962847939999478
        },
        "petal_length": {
          "importance_mean": 0.24000000000000005,
          "importance_std": 0.02231093404090868
        },
        "petal_width": {
          "importance_mean": 0.29466666666666674,
          "importance_std": 0.018571184369578813
        }
      }
    },
    "cv_results": {
      "test_scores": {
        "ACCURACY": {
          "scores": [
            0.9733333333333334,
            0.96
          ],
          "mean": 0.9666666666666667,
          "std": 0.00666666666666671,
          "min": 0.96,
          "max": 0.9733333333333334
        },
        "F1": {
          "scores": [
            0.9732905982905984,
            0.9599839935974389
          ],
          "mean": 0.9666372959440186,
          "std": 0.006653302346579737,
          "min": 0.9599839935974389,
          "max": 0.9732905982905984
        },
        "PRECISION": {
          "scores": [
            0.9753086419753086,
            0.9604700854700855
          ],
          "mean": 0.9678893637226971,
          "std": 0.007419278252611572,
          "min": 0.9604700854700855,
          "max": 0.9753086419753086
        },
        "RECALL": {
          "scores": [
            0.9733333333333334,
            0.96
          ],
          "mean": 0.9666666666666667,
          "std": 0.00666666666666671,
          "min": 0.96,
          "max": 0.9733333333333334
        }
      },
      "train_scores": {
        "ACCURACY": {
          "scores": [
            0.96,
            0.9733333333333334
          ],
          "mean": 0.9666666666666667,
          "std": 0.00666666666666671,
          "min": 0.96,
          "max": 0.9733333333333334
        },
        "F1": {
          "scores": [
            0.9598554797270173,
            0.9732905982905984
          ],
          "mean": 0.9665730390088079,
          "std": 0.006717559281790519,
          "min": 0.9598554797270173,
          "max": 0.9732905982905984
        },
        "PRECISION": {
          "scores": [
            0.9642857142857143,
            0.9753086419753086
          ],
          "mean": 0.9697971781305115,
          "std": 0.005511463844797171,
          "min": 0.9642857142857143,
          "max": 0.9753086419753086
        },
        "RECALL": {
          "scores": [
            0.96,
            0.9733333333333334
          ],
          "mean": 0.9666666666666667,
          "std": 0.00666666666666671,
          "min": 0.96,
          "max": 0.9733333333333334
        }
      },
      "fit_times": "[0.00033498 0.00023818]",
      "score_times": "[0.00155187 0.00152874]",
      "timing": {
        "fit_time_mean": 0.0002865791320800781,
        "fit_time_std": 4.839897155761719e-05,
        "score_time_mean": 0.0015403032302856445,
        "score_time_std": 1.1563301086425781e-05
      },
      "task_type": "classification",
      "cv_folds": 2,
      "data_shape": [
        150,
        4
      ],
      "y_true": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]",
      "y_pred_cv": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]",
      "y_pred_proba_cv": "[[0.74874439 0.18551856 0.06573704]\n [0.7333256  0.20295872 0.06371568]\n [0.73865458 0.19692314 0.06442228]\n [0.73659275 0.19899326 0.06441399]\n [0.74987885 0.18399625 0.0661249 ]\n [0.738953   0.19673765 0.06430935]\n [0.73726546 0.19794957 0.06478497]\n [0.73717978 0.19887863 0.06394159]\n [0.73744869 0.197684   0.06486731]\n [0.74381753 0.19056484 0.06561763]\n [0.74724408 0.18670152 0.0660544 ]\n [0.74883978 0.1853499  0.06581032]\n [0.73707868 0.19874174 0.06417958]\n [0.74650997 0.18613543 0.0673546 ]\n [0.74257673 0.18911917 0.0683041 ]\n [0.73232808 0.07156101 0.19611091]\n [0.74163507 0.19375882 0.06460611]\n [0.73718149 0.19896896 0.06384955]\n [0.7344304  0.20157802 0.06399158]\n [0.74866501 0.18478243 0.06655255]\n [0.73985513 0.19511513 0.06502974]\n [0.74775841 0.18613738 0.06610421]\n [0.74943307 0.18305363 0.06751331]\n [0.71581328 0.22196494 0.06222178]\n [0.73343794 0.20246377 0.06409829]\n [0.73359671 0.20133311 0.06507019]\n [0.73004076 0.20665019 0.06330905]\n [0.737126   0.19902595 0.06384805]\n [0.73612998 0.2001367  0.06373333]\n [0.74660687 0.18771425 0.06567889]\n [0.73348063 0.2026979  0.06382147]\n [0.73701699 0.19815025 0.06483276]\n [0.7429396  0.19121206 0.06584833]\n [0.74249143 0.06930338 0.18820519]\n [0.74222701 0.19241866 0.06535432]\n [0.74573939 0.18861601 0.0656446 ]\n [0.73498672 0.20118028 0.06383299]\n [0.74112457 0.19396728 0.06490815]\n [0.74524323 0.18808978 0.06666699]\n [0.73618988 0.20004333 0.06376678]\n [0.74887461 0.18529058 0.06583482]\n [0.68538491 0.24262986 0.07198523]\n [0.74847092 0.18480664 0.06672245]\n [0.72452455 0.21230066 0.06317478]\n [0.74628829 0.1873555  0.06635621]\n [0.73875078 0.19578624 0.06546297]\n [0.74113559 0.19410589 0.06475852]\n [0.74813184 0.18580426 0.0660639 ]\n [0.74009539 0.19563434 0.06427027]\n [0.73671774 0.19942374 0.06385852]\n [0.0644608  0.72339351 0.21214569]\n [0.06341646 0.72951843 0.20706512]\n [0.06229798 0.7027193  0.23498272]\n [0.06422782 0.73883827 0.19693392]\n [0.06180599 0.70521519 0.23297882]\n [0.06297766 0.73137212 0.20565022]\n [0.06408125 0.71698367 0.21893507]\n [0.07090852 0.74131893 0.18777256]\n [0.06335214 0.73558279 0.20106507]\n [0.06526379 0.73940246 0.19533375]\n [0.06668321 0.73133163 0.20198516]\n [0.06308726 0.73221571 0.20469703]\n [0.06596877 0.7497878  0.18424343]\n [0.06183399 0.71652095 0.22164506]\n [0.06613874 0.75179493 0.18206633]\n [0.06391785 0.73888807 0.19719408]\n [0.06471832 0.73002587 0.20525581]\n [0.06512635 0.75194823 0.18292542]\n [0.06349972 0.68471411 0.25178617]\n [0.06498337 0.74842476 0.18659187]\n [0.06407505 0.69277705 0.2431479 ]\n [0.06395755 0.74827516 0.18776729]\n [0.06213594 0.69666902 0.24119504]\n [0.06330118 0.73640027 0.20029855]\n [0.06378671 0.74539599 0.19081731]\n [0.06357584 0.73782275 0.19860142]\n [0.06276637 0.70609258 0.23114105]\n [0.06199238 0.24776319 0.69024443]\n [0.06268727 0.72068993 0.2166228 ]\n [0.06647216 0.75355319 0.17997465]\n [0.0643849  0.74476677 0.19084833]\n [0.06621124 0.75000232 0.18378644]\n [0.06431331 0.75025808 0.18542861]\n [0.06141163 0.25022858 0.68835979]\n [0.06302685 0.716306   0.22066715]\n [0.06676332 0.7300912  0.20314547]\n [0.06251334 0.71068461 0.22680204]\n [0.06269379 0.70385213 0.23345408]\n [0.06487974 0.74636806 0.1887522 ]\n [0.06363064 0.73619388 0.20017548]\n [0.06386152 0.73797282 0.19816566]\n [0.06266266 0.72781248 0.20952486]\n [0.06386707 0.74591193 0.190221  ]\n [0.06986372 0.74331978 0.1868165 ]\n [0.06396102 0.74083508 0.1952039 ]\n [0.06500274 0.74944996 0.1855473 ]\n [0.06485078 0.74714765 0.18800156]\n [0.06389409 0.74614627 0.18995964]\n [0.07026241 0.74479595 0.18494164]\n [0.06439336 0.74626799 0.18933866]\n [0.06579663 0.18442435 0.74977903]\n [0.0611565  0.22874025 0.71010325]\n [0.06400244 0.18698325 0.74901431]\n [0.06162641 0.21934429 0.71902931]\n [0.06344689 0.18449251 0.75206059]\n [0.06584547 0.1886128  0.74554173]\n [0.06421138 0.69358973 0.24219889]\n [0.06433747 0.19153225 0.74413028]\n [0.06416817 0.19249792 0.74333391]\n [0.06607891 0.18764296 0.74627814]\n [0.06263486 0.22973447 0.70763068]\n [0.06290469 0.203056   0.73403931]\n [0.06357918 0.19315453 0.74326628]\n [0.06179321 0.22793305 0.71027374]\n [0.06484828 0.18576549 0.74938622]\n [0.0635083  0.19334972 0.74314199]\n [0.06203806 0.22503637 0.71292556]\n [0.07029451 0.20484505 0.72486045]\n [0.0674705  0.18519582 0.74733368]\n [0.06325381 0.70592242 0.23082376]\n [0.06431704 0.18713215 0.74855082]\n [0.06295242 0.22444809 0.71259949]\n [0.06650109 0.19093426 0.74256465]\n [0.06127445 0.24005029 0.69867525]\n [0.0640509  0.1982519  0.7376972 ]\n [0.06404472 0.21159145 0.72436383]\n [0.06108425 0.24385503 0.69506072]\n [0.06251513 0.24801428 0.68947059]\n [0.06323333 0.18886209 0.74790457]\n [0.06349237 0.23035106 0.70615657]\n [0.06469004 0.19074972 0.74456024]\n [0.07142754 0.21466512 0.71390734]\n [0.06393421 0.1825653  0.75350049]\n [0.06187427 0.69073557 0.24739015]\n [0.06250007 0.25159886 0.68590107]\n [0.0660629  0.18899149 0.74494561]\n [0.06580631 0.19372968 0.74046401]\n [0.06145646 0.23124247 0.70730107]\n [0.06294367 0.25138965 0.68566668]\n [0.06350854 0.19907719 0.73741427]\n [0.06393426 0.1830512  0.75301454]\n [0.06387788 0.19302018 0.74310195]\n [0.0611565  0.22874025 0.71010325]\n [0.06400998 0.18480514 0.75118488]\n [0.06517177 0.18563146 0.74919677]\n [0.06361766 0.18889294 0.74748939]\n [0.06211963 0.23217651 0.70570387]\n [0.06201395 0.21332939 0.72465666]\n [0.06564589 0.20257079 0.73178331]\n [0.06269566 0.24310564 0.6941987 ]]",
      "saved_files": {
        "original_data": "trained_models/test_matplotlib_fix/e6f5579f-d5ef-48b2-ba67-48a80f15ef51/cross_validation_data/e6f5579f-d5ef-48b2-ba67-48a80f15ef51_original_data.csv",
        "preprocessed_data": "trained_models/test_matplotlib_fix/e6f5579f-d5ef-48b2-ba67-48a80f15ef51/cross_validation_data/e6f5579f-d5ef-48b2-ba67-48a80f15ef51_preprocessed_data.csv",
        "cv_predictions_processed": "trained_models/test_matplotlib_fix/e6f5579f-d5ef-48b2-ba67-48a80f15ef51/cross_validation_data/e6f5579f-d5ef-48b2-ba67-48a80f15ef51_cv_predictions_processed.csv",
        "cv_predictions_original": "trained_models/test_matplotlib_fix/e6f5579f-d5ef-48b2-ba67-48a80f15ef51/cross_validation_data/e6f5579f-d5ef-48b2-ba67-48a80f15ef51_cv_predictions_original.csv",
        "roc_curves": "trained_models/test_matplotlib_fix/e6f5579f-d5ef-48b2-ba67-48a80f15ef51/cross_validation_data/e6f5579f-d5ef-48b2-ba67-48a80f15ef51_roc_curves.png"
      },
      "cv_predictions": {
        "y_true_processed": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]",
        "y_pred_processed": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]",
        "y_pred_proba_processed": "[[0.74874439 0.18551856 0.06573704]\n [0.7333256  0.20295872 0.06371568]\n [0.73865458 0.19692314 0.06442228]\n [0.73659275 0.19899326 0.06441399]\n [0.74987885 0.18399625 0.0661249 ]\n [0.738953   0.19673765 0.06430935]\n [0.73726546 0.19794957 0.06478497]\n [0.73717978 0.19887863 0.06394159]\n [0.73744869 0.197684   0.06486731]\n [0.74381753 0.19056484 0.06561763]\n [0.74724408 0.18670152 0.0660544 ]\n [0.74883978 0.1853499  0.06581032]\n [0.73707868 0.19874174 0.06417958]\n [0.74650997 0.18613543 0.0673546 ]\n [0.74257673 0.18911917 0.0683041 ]\n [0.73232808 0.07156101 0.19611091]\n [0.74163507 0.19375882 0.06460611]\n [0.73718149 0.19896896 0.06384955]\n [0.7344304  0.20157802 0.06399158]\n [0.74866501 0.18478243 0.06655255]\n [0.73985513 0.19511513 0.06502974]\n [0.74775841 0.18613738 0.06610421]\n [0.74943307 0.18305363 0.06751331]\n [0.71581328 0.22196494 0.06222178]\n [0.73343794 0.20246377 0.06409829]\n [0.73359671 0.20133311 0.06507019]\n [0.73004076 0.20665019 0.06330905]\n [0.737126   0.19902595 0.06384805]\n [0.73612998 0.2001367  0.06373333]\n [0.74660687 0.18771425 0.06567889]\n [0.73348063 0.2026979  0.06382147]\n [0.73701699 0.19815025 0.06483276]\n [0.7429396  0.19121206 0.06584833]\n [0.74249143 0.06930338 0.18820519]\n [0.74222701 0.19241866 0.06535432]\n [0.74573939 0.18861601 0.0656446 ]\n [0.73498672 0.20118028 0.06383299]\n [0.74112457 0.19396728 0.06490815]\n [0.74524323 0.18808978 0.06666699]\n [0.73618988 0.20004333 0.06376678]\n [0.74887461 0.18529058 0.06583482]\n [0.68538491 0.24262986 0.07198523]\n [0.74847092 0.18480664 0.06672245]\n [0.72452455 0.21230066 0.06317478]\n [0.74628829 0.1873555  0.06635621]\n [0.73875078 0.19578624 0.06546297]\n [0.74113559 0.19410589 0.06475852]\n [0.74813184 0.18580426 0.0660639 ]\n [0.74009539 0.19563434 0.06427027]\n [0.73671774 0.19942374 0.06385852]\n [0.0644608  0.72339351 0.21214569]\n [0.06341646 0.72951843 0.20706512]\n [0.06229798 0.7027193  0.23498272]\n [0.06422782 0.73883827 0.19693392]\n [0.06180599 0.70521519 0.23297882]\n [0.06297766 0.73137212 0.20565022]\n [0.06408125 0.71698367 0.21893507]\n [0.07090852 0.74131893 0.18777256]\n [0.06335214 0.73558279 0.20106507]\n [0.06526379 0.73940246 0.19533375]\n [0.06668321 0.73133163 0.20198516]\n [0.06308726 0.73221571 0.20469703]\n [0.06596877 0.7497878  0.18424343]\n [0.06183399 0.71652095 0.22164506]\n [0.06613874 0.75179493 0.18206633]\n [0.06391785 0.73888807 0.19719408]\n [0.06471832 0.73002587 0.20525581]\n [0.06512635 0.75194823 0.18292542]\n [0.06349972 0.68471411 0.25178617]\n [0.06498337 0.74842476 0.18659187]\n [0.06407505 0.69277705 0.2431479 ]\n [0.06395755 0.74827516 0.18776729]\n [0.06213594 0.69666902 0.24119504]\n [0.06330118 0.73640027 0.20029855]\n [0.06378671 0.74539599 0.19081731]\n [0.06357584 0.73782275 0.19860142]\n [0.06276637 0.70609258 0.23114105]\n [0.06199238 0.24776319 0.69024443]\n [0.06268727 0.72068993 0.2166228 ]\n [0.06647216 0.75355319 0.17997465]\n [0.0643849  0.74476677 0.19084833]\n [0.06621124 0.75000232 0.18378644]\n [0.06431331 0.75025808 0.18542861]\n [0.06141163 0.25022858 0.68835979]\n [0.06302685 0.716306   0.22066715]\n [0.06676332 0.7300912  0.20314547]\n [0.06251334 0.71068461 0.22680204]\n [0.06269379 0.70385213 0.23345408]\n [0.06487974 0.74636806 0.1887522 ]\n [0.06363064 0.73619388 0.20017548]\n [0.06386152 0.73797282 0.19816566]\n [0.06266266 0.72781248 0.20952486]\n [0.06386707 0.74591193 0.190221  ]\n [0.06986372 0.74331978 0.1868165 ]\n [0.06396102 0.74083508 0.1952039 ]\n [0.06500274 0.74944996 0.1855473 ]\n [0.06485078 0.74714765 0.18800156]\n [0.06389409 0.74614627 0.18995964]\n [0.07026241 0.74479595 0.18494164]\n [0.06439336 0.74626799 0.18933866]\n [0.06579663 0.18442435 0.74977903]\n [0.0611565  0.22874025 0.71010325]\n [0.06400244 0.18698325 0.74901431]\n [0.06162641 0.21934429 0.71902931]\n [0.06344689 0.18449251 0.75206059]\n [0.06584547 0.1886128  0.74554173]\n [0.06421138 0.69358973 0.24219889]\n [0.06433747 0.19153225 0.74413028]\n [0.06416817 0.19249792 0.74333391]\n [0.06607891 0.18764296 0.74627814]\n [0.06263486 0.22973447 0.70763068]\n [0.06290469 0.203056   0.73403931]\n [0.06357918 0.19315453 0.74326628]\n [0.06179321 0.22793305 0.71027374]\n [0.06484828 0.18576549 0.74938622]\n [0.0635083  0.19334972 0.74314199]\n [0.06203806 0.22503637 0.71292556]\n [0.07029451 0.20484505 0.72486045]\n [0.0674705  0.18519582 0.74733368]\n [0.06325381 0.70592242 0.23082376]\n [0.06431704 0.18713215 0.74855082]\n [0.06295242 0.22444809 0.71259949]\n [0.06650109 0.19093426 0.74256465]\n [0.06127445 0.24005029 0.69867525]\n [0.0640509  0.1982519  0.7376972 ]\n [0.06404472 0.21159145 0.72436383]\n [0.06108425 0.24385503 0.69506072]\n [0.06251513 0.24801428 0.68947059]\n [0.06323333 0.18886209 0.74790457]\n [0.06349237 0.23035106 0.70615657]\n [0.06469004 0.19074972 0.74456024]\n [0.07142754 0.21466512 0.71390734]\n [0.06393421 0.1825653  0.75350049]\n [0.06187427 0.69073557 0.24739015]\n [0.06250007 0.25159886 0.68590107]\n [0.0660629  0.18899149 0.74494561]\n [0.06580631 0.19372968 0.74046401]\n [0.06145646 0.23124247 0.70730107]\n [0.06294367 0.25138965 0.68566668]\n [0.06350854 0.19907719 0.73741427]\n [0.06393426 0.1830512  0.75301454]\n [0.06387788 0.19302018 0.74310195]\n [0.0611565  0.22874025 0.71010325]\n [0.06400998 0.18480514 0.75118488]\n [0.06517177 0.18563146 0.74919677]\n [0.06361766 0.18889294 0.74748939]\n [0.06211963 0.23217651 0.70570387]\n [0.06201395 0.21332939 0.72465666]\n [0.06564589 0.20257079 0.73178331]\n [0.06269566 0.24310564 0.6941987 ]]",
        "y_true_original": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']",
        "y_pred_original": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'virginica' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'virginica'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'versicolor' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'versicolor' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"
      }
    },
    "performance_summary": "Classification model achieved 0.967±0.007 accuracy and 0.967 F1-score (2-fold CV)",
    "trained_report_summary_html_path": "You can find the html trained report summary in http://localhost:8120/static/test_matplotlib_fix/e6f5579f-d5ef-48b2-ba67-48a80f15ef51/training_report.html",
    "trained_details": "All detailed training data are saved in http://localhost:8120/download/file/test_matplotlib_fix/archives/e6f5579f-d5ef-48b2-ba67-48a80f15ef51_20250922_021611.zip,\n                which can be downloaded by users for reproducibility and academic research reference."
  }
}